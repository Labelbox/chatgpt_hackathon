# Challenge

  - You’re tasked with fine-tuning ChatGPT for a specific task - sentiment analysis in Reddit posts…but have a limited budget for model training 
  - Due to this budget, you can only fine-tune ChatGPT **three times**, each time you only get 2000 incremental training data rows
    - So, you can train on 2000 data rows in Round 1, 4000 data rows in Round 2, and 6000 data rows in Round 3
    

# How to Enter

  - Create teams of three with a unique team name - prove your .edu email to your professor and we will create a Labelbox account for you and your team in the hackathon workspace
  - Follow the notebooks in this repo to register, send curated data rows to a model run, and fine tune ChatGPT on curated data rows
  
# Key Steps
  - Register your team in Labelbox
  - Using the Labelbox Catalog, curate a training set to 

# 

|            Notebook            |  Github  |    Google Colab   |
| ------------------------------ | -------- | ----------------- |
| Register Your Team            | [![Github](https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white)](notebooks/register.ipynb)  | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1lKEENBtcj4vVzuWmYtX_qaRplbxI9TGf) |
| Send Curated Data Rows to Model Run        | [![Github](https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white)](notebooks/model-run.ipynb)  | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1JHlGlkLlVeL0mXmBrpp9z423vkdTYr5W) |
| Fine-Tune ChatGPT based on Data Rows in Model Run     | [![Github](https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white)](notebooks/fine-tune.ipynb)  | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Vg-D0b3Jif8oBW4LF4ksVdnLA4JpshfP) |
------
    
  
